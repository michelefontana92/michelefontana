---
abstract: Federated Learning has witnessed an increasing popularity in the past few years for its ability to train Machine Learning models in critical contexts, using private data without moving them. Most of the approaches in the literature are focused on mobile environments, where mobile devices contain the data of single users, and typically deal with images or text data. In this paper, we define HOLDA, a novel federated learning approach tailored for training machine learning models on data distributed over federated organizations hierarchically organized. Our method focuses on the generalization capabilities of the neural network models, providing a new mechanism for selecting their best weights. In addition, it is tailored for tabular data. We empirically test the performance of our approach on two different tabular datasets, showing excellent results in terms of performance and generalization capabilities. Then, we also tackle the problem of assessing the privacy risk of users represented in the training data. In particular, we empirically show, by attacking the HOLDA models with the Membership Inference Attack, that the privacy of the users in the training data may have high risk.

authors:
- admin
- Francesca Naretto
- Anna Monreale

date: "2021-12-21"
doi: "10.1109/PST52912.2021.9647753"

featured: false


publication: In *18th International Conference on Privacy, Security and Trust, PST 2021, Auckland, New Zealand, December 13-15, 2021*
publication_types:
- "1"
publishDate: "2021-12-21"


tags:
- HOLDA
- Federated Learning
- Privacy risk assessment

title: A new approach for cross-silo federated learning and its privacy risks
url_code: https://github.com/michelefontana92/HOLDA
url_pdf: 	https://doi.org/10.1109/PST52912.2021.9647753
url_slides: "PST2021_Presentation.pdf"
---
